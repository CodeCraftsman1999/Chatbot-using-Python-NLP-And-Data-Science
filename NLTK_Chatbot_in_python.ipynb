{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j5qaJHOkCSR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJwcKkrQlzvM"
      },
      "outputs": [],
      "source": [
        "f = open('/content/Chatbot.txt','r',errors = 'ignore')\n",
        "raw_doc = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw.doc"
      ],
      "metadata": {
        "id": "ZfV2EkP6mOMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDZhzk3yyhc9",
        "outputId": "be9a2f9d-78c4-440e-a069-093e39a2eba8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_doc = raw_doc.lower() # Converting entire text to lowercase\n",
        "nltk.download('punkt')  #Using the putkt tokenizer\n",
        "nltk.download('wordnet')  #using the wordnet dictionary\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pxlDKDJznJ8"
      },
      "outputs": [],
      "source": [
        "sentence_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc"
      ],
      "metadata": {
        "id": "4e4VVqnemTPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr0CWVgc0F6j"
      },
      "source": [
        "After Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgujV6mp0M00",
        "outputId": "4d768cd9-bae8-47bf-c101-7af8f24c9553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['chatbot-wikipedia\\n\\n\\n\\n\\n-------------------------------------------------------------\\nchatbot sequences\\ncompany internal platforms\\ncustomer service\\nhealthcare\\npolitics\\ngovernment\\ntoys\\nmalicious use\\ndata security\\nlimitations of chatbots\\nchatbots and jobs\\nsee also\\nreferences\\nfurther reading\\nexternal links\\nchatbot\\n\\narticle\\ntalk\\nread\\nedit\\nview history\\n\\ntools\\nfrom wikipedia, the free encyclopedia\\nfor the bot-creation software, see chatbot.',\n",
              " 'for bots on internet relay chat, see irc bot.',\n",
              " 'parts of this article (those related to everything, particularly sections after the intro) need to be updated.',\n",
              " 'the reason given is: this article is using citations from 1970 and virtually all claims about conversational capabilities are at least ten years out of date (for example the turing test was arguably made obsolete years ago by transformer models).',\n",
              " 'please help update this article to reflect recent events or newly available information.']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70jePtsg0Xns",
        "outputId": "a30ae677-399f-4a80-8464-447bc1e346b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['chatbot-wikipedia', '--', '--', '--', '--']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZPBDPOr0qct"
      },
      "source": [
        "Performing Text-PreProcessing Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC9IXQN-008N"
      },
      "outputs": [],
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punc_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7rGAiDa2xbz"
      },
      "source": [
        "Define Greeting Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkhWIX5G22IN"
      },
      "outputs": [],
      "source": [
        "greet_inputs = ('hello','hi','whassup','how are you?')\n",
        "greet_responses = ('hi','Hey','Hey There!','There there!!')\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in greet_inputs:\n",
        "      return random.choice(greet_responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP__iaxt39Dd"
      },
      "source": [
        "Response Generation by the Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKw9hABG62jz"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTT6JFVU8-G4"
      },
      "outputs": [],
      "source": [
        "from re import T\n",
        "def response(user_response):\n",
        "  robo1_response = ''\n",
        "  TfidVec = TfidfVectorizer(tokenizer = LemNormalize,stop_words = 'english')\n",
        "  tfidf = TfidVec.fit_transform(sentence_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf == 0):\n",
        "    robo1_response = robo1_response + \"Iam sorry. Unable to undestand you!\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response + sentence_tokens[idx]\n",
        "    return robo1_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI2qqsWQCTYm"
      },
      "source": [
        "Defining the ChatFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjZFwi7oCWzW",
        "outputId": "685cca67-117b-4dc7-bae3-daffb0ae4da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am the Learning Bot.Start typing your text after greeting to talk to me.For ending convo type bye!\n",
            "Bot Hey\n",
            "Bot: chatbot competitions focus on the turing test or more specific goals.\n"
          ]
        }
      ],
      "source": [
        "flag = True\n",
        "print('Hello! I am the Learning Bot.Start typing your text after greeting to talk to me.For ending convo type bye!')\n",
        "while(flag ==True):\n",
        "  user_response = input()\n",
        "  user_response = user_response.lower()\n",
        "  if(user_response != 'bye'):\n",
        "    if(user_response == 'thank you' or user_response == 'thanks'):\n",
        "      flag = False\n",
        "      print('Bot:You are Welcome..')\n",
        "    else:\n",
        "      if(greet(user_response) != None):\n",
        "        print('Bot '+greet(user_response))\n",
        "      else:\n",
        "        sentence_tokens.append(user_response)\n",
        "        word_tokens = word_tokens +nltk.word_tokenize(user_response)\n",
        "        final_words = list(set(word_tokens))\n",
        "        print('Bot: ',end = '')\n",
        "        print(response(user_response))\n",
        "        sentence_tokens.remove(user_response)\n",
        "  else:\n",
        "    flag = False\n",
        "    print('Bot: Goodbye!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKHUtHJwGAlH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}